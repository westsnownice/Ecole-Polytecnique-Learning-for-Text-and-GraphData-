{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import operator\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from joblib import Parallel, delayed\n",
    "import tqdm\n",
    "import string\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import scipy.sparse\n",
    "import holidays\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "path_to_data = \"/Users/zacharie/Documents/AICCours/MVA/textGraphData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv(path_to_data + 'training_set.csv', sep=',', header=0).values\n",
    "training_info = pd.read_csv(path_to_data + 'training_info.csv', sep=',', header=0, parse_dates = [1]).values\n",
    "test = pd.read_csv(path_to_data + 'test_set.csv', sep=',', header=0).values\n",
    "test_info = pd.read_csv(path_to_data + 'test_info.csv', sep=',', header=0, parse_dates = [1]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "integrate_training = []\n",
    "for each_line in training:\n",
    "    sender = each_line[0]\n",
    "    ids = each_line[-1].split(' ')\n",
    "    for my_id in ids:\n",
    "        tmp = training_info[training_info[:,0]==int(my_id)]\n",
    "        if tmp[0,1] > \"1998-01-01\":\n",
    "            integrate_training.append([sender,tmp[0,0],tmp[0,1],tmp[0,2], tmp[0,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43411 43613\n"
     ]
    }
   ],
   "source": [
    "print len(integrate_training), len(training_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=43411, step=1)\n"
     ]
    }
   ],
   "source": [
    "integrate_training = pd.DataFrame(integrate_training, columns=['sender','mid','date','body','recipients'])\n",
    "print integrate_training.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "integrate_test = []\n",
    "for each_line in test:\n",
    "    sender = each_line[0]\n",
    "    ids = each_line[-1].split(' ')\n",
    "    for my_id in ids:\n",
    "        tmp = test_info[test_info[:,0]==int(my_id)]\n",
    "        integrate_test.append([sender,tmp[0,0],tmp[0,1],tmp[0,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=2362, step=1)\n"
     ]
    }
   ],
   "source": [
    "integrate_test = pd.DataFrame(integrate_test, columns=['sender','mid','date','body'])\n",
    "print integrate_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998-12-21 05:29:00\n",
      "2001-11-01 19:12:34\n",
      "RangeIndex(start=0, stop=43411, step=1)\n"
     ]
    }
   ],
   "source": [
    "print integrate_training['date'].min()\n",
    "print integrate_training['date'].max()\n",
    "print integrate_training.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001-11-02 05:25:29\n",
      "2002-06-24 13:15:28\n",
      "RangeIndex(start=0, stop=2362, step=1)\n"
     ]
    }
   ],
   "source": [
    "print integrate_test['date'].min()\n",
    "print integrate_test['date'].max()\n",
    "print integrate_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Counter(integrate_training.sender.tolist())\n",
    "# local_recs_list = integrate_training['recipients'].tolist()\n",
    "# recs_temp = [r for rec in local_recs_list for r in rec.split(' ') if '@' in r]\n",
    "# rec_occ = dict(Counter(recs_temp))\n",
    "# sorted_rec_occ = sorted(rec_occ.items(), key=operator.itemgetter(1), reverse = True)\n",
    "# print len(sorted_rec_occ)\n",
    "# hehe = dict(Counter(integrate_training['sender'].tolist()))\n",
    "# sorted_sender_occ = sorted(hehe.items(), key=operator.itemgetter(1), reverse = True)\n",
    "# print sorted_sender_occ\n",
    "# hehe = dict(Counter(integrate_test['sender'].tolist()))\n",
    "# sorted_sender_occ = sorted(hehe.items(), key=operator.itemgetter(1), reverse = True)\n",
    "# print sorted_sender_occ\n",
    "print set(integrate_test['sender'].tolist())== set(integrate_training['sender'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=43411, step=1)\n",
      "RangeIndex(start=0, stop=2362, step=1)\n"
     ]
    }
   ],
   "source": [
    "print integrate_training['body'].index\n",
    "print integrate_test['body'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "integrate_training['date'] = integrate_training['date'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998-12-21 05:29:00\n",
      "2001-11-01 19:12:34\n",
      "2001-11-02 05:25:29\n",
      "2002-06-24 13:15:28\n"
     ]
    }
   ],
   "source": [
    "#integrate_test\n",
    "print integrate_training['date'].min()\n",
    "print integrate_training['date'].max()\n",
    "print integrate_test['date'].min()\n",
    "print integrate_test['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# remove dashes and apostrophes from punctuation marks\n",
    "punct = string.punctuation.replace('-', '').replace(\"'\",'')\n",
    "stpwds = nltk.corpus.stopwords.words('english')\n",
    "# regex to match intra-word dashes and intra-word apostrophes\n",
    "my_regex = re.compile(r\"(\\b[-']\\b)|[\\W_]\")\n",
    "stemmering = nltk.PorterStemmer()\n",
    "# performs basic pre-processing\n",
    "# note: we do not lowercase for consistency with Google News embeddings\n",
    "def clean_string(string, punct=punct, my_regex=my_regex):\n",
    "    # remove formatting\n",
    "    str = re.sub('\\s+', ' ', string)\n",
    "    # remove punctuation (preserving dashes)\n",
    "    str = ''.join(l for l in str if l not in punct)\n",
    "    # remove dashes that are not intra-word\n",
    "    str = my_regex.sub(lambda x: (x.group(1) if x.group(1) else ' '), str)\n",
    "    # strip extra white space\n",
    "    str = re.sub(' +',' ',str)\n",
    "    # strip leading and trailing white space\n",
    "    str = str.strip()\n",
    "    # tokenize (split based on whitespace)\n",
    "    tokens = str.split(' ')\n",
    "    # remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stpwds]\n",
    "    # remove tokens less than 2 characters in size\n",
    "    # tokens = [token for token in tokens if len(token)>=2]\n",
    "    tokens = [stemmering.stem(token.lower()) for token in tokens if len(token)>=2]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def stemmering_sentences_messages(X):\n",
    "    sentences_stem = Parallel(n_jobs=4)(delayed(clean_string)(sentence) for sentence in tqdm.tqdm(X, desc=\"clean sentences\"))\n",
    "    return sentences_stem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clean sentences: 100%|██████████| 43411/43411 [01:30<00:00, 477.98it/s]\n"
     ]
    }
   ],
   "source": [
    "integrate_training['body'] = stemmering_sentences_messages(integrate_training['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clean sentences: 100%|██████████| 2362/2362 [00:05<00:00, 434.91it/s]\n"
     ]
    }
   ],
   "source": [
    "integrate_test['body'] = stemmering_sentences_messages(integrate_test['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# us_holidays = holidays.UnitedStates()\n",
    "# Counter(integrate_test['date'].apply(lambda x: int(x in us_holidays)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# integrate_test['holiday'] = integrate_test['date'].apply(lambda x: int(x in us_holidays))\n",
    "# integrate_training['holiday'] = integrate_training['date'].apply(lambda x: int(x in us_holidays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# integrate_test['quarter'] = integrate_test['date'].dt.quarter\n",
    "# integrate_training['quarter'] = integrate_training['date'].dt.quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "integrate_training['month'] = integrate_training['date'].dt.month.map(str)\n",
    "integrate_training['day'] = integrate_training['date'].dt.day.map(str)\n",
    "integrate_training['hour'] = integrate_training['date'].dt.hour.map(str)\n",
    "integrate_training['minute'] = integrate_training['date'].dt.minute.map(str)\n",
    "integrate_training['date_body'] = integrate_training[['month', 'day', 'hour', 'minute', 'body']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "integrate_test['month'] = integrate_test['date'].dt.month.map(str)\n",
    "integrate_test['day'] = integrate_test['date'].dt.day.map(str)\n",
    "integrate_test['hour'] = integrate_test['date'].dt.hour.map(str)\n",
    "integrate_test['minute'] = integrate_test['date'].dt.minute.map(str)\n",
    "integrate_test['date_body'] = integrate_test[['month', 'day', 'hour', 'minute', 'body']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# integrate_test.drop(labels=['date', 'body', 'month', 'day', 'hour', 'minute'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'sender', u'mid', u'date', u'body', u'month', u'day', u'hour',\n",
      "       u'minute', u'date_body'],\n",
      "      dtype='object')\n",
      "Index([u'sender', u'mid', u'date', u'body', u'recipients', u'month', u'day',\n",
      "       u'hour', u'minute', u'date_body'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print integrate_test.columns\n",
    "print integrate_training.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# integrate_training_1 = pd.get_dummies(integrate_training,columns=['sender'])\n",
    "# integrate_test_1 = pd.get_dummies(integrate_test,columns=['sender'])\n",
    "# integrate_training_1.insert(0, 'sender', integrate_training['sender'])\n",
    "# integrate_test_1.insert(0, 'sender', integrate_test['sender'])\n",
    "# integrate_training = integrate_training_1\n",
    "# integrate_test = integrate_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# integrate_training = pd.get_dummies(integrate_training, prefix=['q','m','d','h'], columns=['quarter', 'month', 'day', 'hour'])\n",
    "# integrate_test = pd.get_dummies(integrate_test, prefix=['q','m','d','h'], columns=['quarter', 'month', 'day', 'hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43411, 10)\n",
      "(2362, 9)\n"
     ]
    }
   ],
   "source": [
    "print integrate_training.shape\n",
    "print integrate_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X = integrate_training['date_body'].tolist() + integrate_test['date_body'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(min_df=10, max_df=0.9,stop_words='english',analyzer='word', norm='l2', lowercase=True, tokenizer=nltk.word_tokenize, ngram_range=(1, 1))\n",
    "X_sentences = vect.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45773, 23009)\n"
     ]
    }
   ],
   "source": [
    "print X_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "integrate_training_1 = pd.get_dummies(integrate_training,columns=['sender'])\n",
    "integrate_test_1 = pd.get_dummies(integrate_test,columns=['sender'])\n",
    "integrate_training_1.insert(0, 'sender', integrate_training['sender'])\n",
    "integrate_test_1.insert(0, 'sender', integrate_test['sender'])\n",
    "integrate_training = integrate_training_1\n",
    "integrate_test = integrate_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'sender', u'mid', u'date', u'body', u'recipients', u'month', u'day',\n",
      "       u'hour', u'minute', u'date_body',\n",
      "       ...\n",
      "       u'sender_susan.scott@enron.com', u'sender_suzanne.adams@enron.com',\n",
      "       u'sender_sylvia.hu@enron.com', u'sender_tanya.rohauer@enron.com',\n",
      "       u'sender_taylor@enron.com', u'sender_tim.belden@enron.com',\n",
      "       u'sender_tori.kuykendall@enron.com', u'sender_vkaminski@aol.com',\n",
      "       u'sender_w..cantrell@enron.com', u'sender_wsmith@wordsmith.org'],\n",
      "      dtype='object', length=135)\n",
      "Index([u'sender', u'mid', u'date', u'body', u'month', u'day', u'hour',\n",
      "       u'minute', u'date_body', u'sender_alan.aronowitz@enron.com',\n",
      "       ...\n",
      "       u'sender_susan.scott@enron.com', u'sender_suzanne.adams@enron.com',\n",
      "       u'sender_sylvia.hu@enron.com', u'sender_tanya.rohauer@enron.com',\n",
      "       u'sender_taylor@enron.com', u'sender_tim.belden@enron.com',\n",
      "       u'sender_tori.kuykendall@enron.com', u'sender_vkaminski@aol.com',\n",
      "       u'sender_w..cantrell@enron.com', u'sender_wsmith@wordsmith.org'],\n",
      "      dtype='object', length=134)\n"
     ]
    }
   ],
   "source": [
    "print integrate_training.columns\n",
    "print integrate_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45773, 125)\n"
     ]
    }
   ],
   "source": [
    "tmp_sender_array = scipy.sparse.vstack([integrate_training.iloc[:, 10:].as_matrix(), integrate_test.iloc[:, 9:].as_matrix()])\n",
    "print tmp_sender_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X_sentences_4 = scipy.sparse.hstack([X_sentences, tmp_sender_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./' + 'processed_X_sentences_4.pkl', 'wb') as f:\n",
    "    pickle.dump(X_sentences_4, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./' + 'processed_X_sentences_4.pkl', 'rb') as f:\n",
    "    X_sentences_4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# svd = TruncatedSVD(n_components=500, random_state=42)\n",
    "# X_sentences_reduced = svd.fit_transform(X_sentences_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43411\n",
      "2362\n"
     ]
    }
   ],
   "source": [
    "len_training = integrate_training.shape[0]\n",
    "print len_training\n",
    "len_test = integrate_test.shape[0]\n",
    "print len_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X_training = X_sentences_4.toarray()[:len_training,:]\n",
    "X_test = X_sentences_4.toarray()[len_training:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print len(X_training) == len_training\n",
    "print len(X_test) == len_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=4, n_neighbors=30, p=2, radius=2.0)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=30, radius=2.0, n_jobs = 4)\n",
    "# neigh = NearestNeighbors(n_neighbors=30, metric=cosine_similarity, n_jobs=4)\n",
    "neigh.fit(X_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "distance, index = neigh.kneighbors(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "integrate_training['sender'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_per_test_mid = []\n",
    "k_constant=10\n",
    "for i , series in integrate_test.iterrows():\n",
    "    row = series.tolist()\n",
    "    sender = row[0]\n",
    "    mid = row[1]\n",
    "    index_per_sender = integrate_training[integrate_training['sender'] == sender].index.tolist()\n",
    "    index_total = np.intersect1d(np.array(index_per_sender), index[i])\n",
    "    local_recs_list = integrate_training.iloc[index_total]['recipients'].tolist()\n",
    "    recs_temp = [r for rec in local_recs_list for r in rec.split(' ') if '@' in r]\n",
    "    rec_occ = dict(Counter(recs_temp))\n",
    "    sorted_rec_occ = sorted(rec_occ.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    k_most = [tuple[0] for tuple in sorted_rec_occ[:k_constant]]\n",
    "    if len(k_most) <= k_constant:\n",
    "        print '!'\n",
    "    predictions_per_test_mid.append([mid, k_most])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "path_to_results = \"/Users/zacharie/Documents/AICCours/MVA/textGraphData/\"\n",
    "with open(path_to_results + 'predictions_frequency_11.txt', 'wb') as my_file:\n",
    "    my_file.write('mid,recipients' + '\\n')\n",
    "    for mid_k_most in predictions_per_test_mid:\n",
    "        my_file.write(str(mid_k_most[0]) + ',' + ' '.join(mid_k_most[-1]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# predictions_per_test_mid = []\n",
    "# k_constant=10\n",
    "# for line in test:\n",
    "#     sender = line[0]\n",
    "#     print sender\n",
    "#     index_per_sender_training = np.array(integrate_training[integrate_training['sender'] == sender].index.tolist())\n",
    "#     nei = NearestNeighbors(n_neighbors=20, radius=2.0, n_jobs = -1)\n",
    "#     nei.fit(X_training[index_per_sender_training,])\n",
    "#     index_per_sender_test = integrate_test[integrate_test['sender'] == sender].index.tolist()\n",
    "#     mids = integrate_test[integrate_test['sender'] == sender]['mid'].tolist()\n",
    "#     neigh_test_index = nei.kneighbors(X_test[index_per_sender_test, ], return_distance=False)\n",
    "#     for i, neigh_index in enumerate(neigh_test_index):\n",
    "#         local_recs_list = integrate_training.iloc[index_per_sender_training[neigh_index]]['recipients'].tolist()\n",
    "#         recs_temp = [r for rec in local_recs_list for r in rec.split(' ') if '@' in r]\n",
    "#         rec_occ = dict(Counter(recs_temp))\n",
    "#         # order by frequency\n",
    "#         sorted_rec_occ = sorted(rec_occ.items(), key=operator.itemgetter(1), reverse = True)\n",
    "#         k_most = [tuple[0] for tuple in sorted_rec_occ[:k_constant]]\n",
    "#         predictions_per_test_mid.append([mids[i], k_most])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": "main_5.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
